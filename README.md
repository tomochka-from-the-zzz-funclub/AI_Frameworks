# AI_Frameworks



# Лабораторные работы по курсу: Прикладные системы и фреймворки ИИ
Выполнила: Гусейнова Т.М., группа М8О-407Б-22

## Выбранные датасеты

Набор данных для задачи классификации: https://www.kaggle.com/datasets/muratkokludataset/date-fruit-datasets

Набор данных для задачи регрессии: https://www.kaggle.com/datasets/niteshyadav3103/concrete-compressive-strength

## Итоги работы

В таблице указаны значения метрик Accuracy и F1-Score для классификации; RMSE и R² для регрессии.

<table>
    <tr>
        <th rowspan="1">Алгоритм</th>
        <th>Задача</th>
        <th>Бейзлайн</th>
        <th>Улучшенный бейзлайн</th>
        <th>Самостоятельная имплементация алгоритма</th>
    </tr>
    <tr>
        <td rowspan="2">KNN</td>
        <td>классификация</td>
        <td>Acc=0.7111; F1=0.6919</td>
        <td>Acc=0.9222; F1=0.9222</td>
        <td>Acc=0.9222; F1=0.9213</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>RMSE=8.2983; R²=0.7328</td>
        <td>RMSE=7.2531; R²=0.7958</td>
        <td>RMSE=7.1210; R²=0.8032</td>
    </tr>
    <tr>
        <td rowspan="2">Линейные модели</td>
        <td>классификация</td>
        <td>Acc=0.9278; F1=0.9263</td>
        <td>Acc=0.9278; F1=0.9263</td>
        <td>Acc=0.0611; F1=0.0189</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>RMSE=9.7967; R²=0.6275</td>
        <td>RMSE=9.7951; R²=0.6276</td>
        <td>RMSE=9.7967; R²=0.6275</td>
    </tr>
    <tr>
        <td rowspan="2">Решающее дерево</td>
        <td>классификация</td>
        <td>Acc=0.8056; F1=0.7969</td>
        <td>Acc=0.8556; F1=0.8587</td>
        <td>Acc=0.8389; F1=0.8429</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>RMSE=9.5792; R²=0.6439</td>
        <td>RMSE=6.8943; R²=0.8155</td>
        <td>RMSE=8.4854; R²=0.7206</td>
    </tr>
    <tr>
        <td rowspan="2">Случайный лес</td>
        <td>классификация</td>
        <td>Acc=0.9222; F1=0.9214</td>
        <td>Acc=0.9389; F1=0.9388</td>
        <td>Acc=0.8667; F1=0.8678</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>RMSE=5.5318; R²=0.8812</td>
        <td>RMSE=5.4137; R²=0.8863</td>
        <td>RMSE=7.4933; R²=0.7821</td>
    </tr>
    <tr>
        <td rowspan="2">Градиентный бустинг</td>
        <td>классификация</td>
        <td>Acc=0.8778; F1=0.8807</td>
        <td>Acc=0.8944; F1=0.8962</td>
        <td>Acc=0.0056; F1=0.0026</td>
    </tr>
    <tr>
        <td>регрессия</td>
        <td>RMSE=5.5422; R²=0.8808</td>
        <td>RMSE=4.4988; R²=0.9215</td>
        <td>RMSE=10.2992; R²=0.5884</td>
    </tr>
</table>

## Вывод

**Лучшие результаты:** 
- Для классификации лучше всего работают линейные модели и случайный лес из sklearn (Accuracy ~0.93). 
- Для регрессии лучше всего показывает себя градиентный бустинг из sklearn (RMSE=4.50, R²=0.92).

**Самостоятельные реализации:**
- KNN и решающие деревья реализованы хорошо — результаты близки к sklearn.
- Случайный лес работает хуже, но приемлемо.
- Линейные модели и градиентный бустинг в самостоятельной реализации работают заместно хуже.

Sklearn стабильно показывает лучшие результаты. Простые алгоритмы (KNN, деревья) можно реализовать самостоятельно с хорошим качеством. Сложные алгоритмы (бустинг, линейные модели с оптимизацией) лучше использовать из библиотек.
Итак, лучшей моделью для классификации является *Случайный лес с улучшенным бейзлайном*.
Лучшей моделью для регрессии является *Градиентный бустинг с улучшенным бейзлайном*.
