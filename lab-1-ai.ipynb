{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3400552,"sourceType":"datasetVersion","datasetId":2049845},{"sourceId":7963387,"sourceType":"datasetVersion","datasetId":1328826}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Лабораторная работа №1: Проведение исследований с алгоритмом KNN","metadata":{}},{"cell_type":"markdown","source":"### 1. Выбор начальных условий","metadata":{}},{"cell_type":"markdown","source":"#### Задача классификации","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn numpy pandas matplotlib seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:54.491627Z","iopub.execute_input":"2025-12-03T10:43:54.492029Z","iopub.status.idle":"2025-12-03T10:43:58.981358Z","shell.execute_reply.started":"2025-12-03T10:43:54.492002Z","shell.execute_reply":"2025-12-03T10:43:58.979001Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:58.984174Z","iopub.execute_input":"2025-12-03T10:43:58.984542Z","iopub.status.idle":"2025-12-03T10:43:58.990627Z","shell.execute_reply.started":"2025-12-03T10:43:58.984508Z","shell.execute_reply":"2025-12-03T10:43:58.989509Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"date_fruit_path = \"/kaggle/input/date-fruit-datasets\"\n\nprint(\"Path to Date Fruit dataset files:\", date_fruit_path)\n\n# Проверка содержимого папки\nif os.path.exists(date_fruit_path):\n    files = os.listdir(date_fruit_path)\n    print(\"Files:\", files)\nelse:\n    print(\"Not found\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:58.992045Z","iopub.execute_input":"2025-12-03T10:43:58.992350Z","iopub.status.idle":"2025-12-03T10:43:59.054468Z","shell.execute_reply.started":"2025-12-03T10:43:58.992327Z","shell.execute_reply":"2025-12-03T10:43:59.053290Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Path to Date Fruit dataset files: /kaggle/input/date-fruit-datasets\nFiles: ['Date_Fruit_Datasets']\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# Чтение Excel-файла\ndate_fruit_data = pd.read_excel(f\"{date_fruit_path}/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx\")\n\n# Проверка данных\ndate_fruit_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.056752Z","iopub.execute_input":"2025-12-03T10:43:59.058121Z","iopub.status.idle":"2025-12-03T10:43:59.662940Z","shell.execute_reply.started":"2025-12-03T10:43:59.058086Z","shell.execute_reply":"2025-12-03T10:43:59.661792Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n\n   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n\n   KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n0      4.2287 -59191263232 -50714214400 -39922372608     58.7255     54.9554   \n1      3.1704 -34233065472 -37462601728 -31477794816     50.0259     52.8168   \n2      4.7192 -93948354560 -74738221056 -60311207936     65.4772     59.2860   \n3      8.2618 -32074307584 -32060925952 -29575010304     43.3900     44.1259   \n4      4.4146 -39980974080 -35980042240 -25593278464     52.7743     50.9080   \n\n   ALLdaub4RB  Class  \n0     47.8400  BERHI  \n1     47.8315  BERHI  \n2     51.9378  BERHI  \n3     41.1882  BERHI  \n4     42.6666  BERHI  \n\n[5 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AREA</th>\n      <th>PERIMETER</th>\n      <th>MAJOR_AXIS</th>\n      <th>MINOR_AXIS</th>\n      <th>ECCENTRICITY</th>\n      <th>EQDIASQ</th>\n      <th>SOLIDITY</th>\n      <th>CONVEX_AREA</th>\n      <th>EXTENT</th>\n      <th>ASPECT_RATIO</th>\n      <th>...</th>\n      <th>KurtosisRR</th>\n      <th>KurtosisRG</th>\n      <th>KurtosisRB</th>\n      <th>EntropyRR</th>\n      <th>EntropyRG</th>\n      <th>EntropyRB</th>\n      <th>ALLdaub4RR</th>\n      <th>ALLdaub4RG</th>\n      <th>ALLdaub4RB</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>422163</td>\n      <td>2378.908</td>\n      <td>837.8484</td>\n      <td>645.6693</td>\n      <td>0.6373</td>\n      <td>733.1539</td>\n      <td>0.9947</td>\n      <td>424428</td>\n      <td>0.7831</td>\n      <td>1.2976</td>\n      <td>...</td>\n      <td>3.2370</td>\n      <td>2.9574</td>\n      <td>4.2287</td>\n      <td>-59191263232</td>\n      <td>-50714214400</td>\n      <td>-39922372608</td>\n      <td>58.7255</td>\n      <td>54.9554</td>\n      <td>47.8400</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>338136</td>\n      <td>2085.144</td>\n      <td>723.8198</td>\n      <td>595.2073</td>\n      <td>0.5690</td>\n      <td>656.1464</td>\n      <td>0.9974</td>\n      <td>339014</td>\n      <td>0.7795</td>\n      <td>1.2161</td>\n      <td>...</td>\n      <td>2.6228</td>\n      <td>2.6350</td>\n      <td>3.1704</td>\n      <td>-34233065472</td>\n      <td>-37462601728</td>\n      <td>-31477794816</td>\n      <td>50.0259</td>\n      <td>52.8168</td>\n      <td>47.8315</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>526843</td>\n      <td>2647.394</td>\n      <td>940.7379</td>\n      <td>715.3638</td>\n      <td>0.6494</td>\n      <td>819.0222</td>\n      <td>0.9962</td>\n      <td>528876</td>\n      <td>0.7657</td>\n      <td>1.3150</td>\n      <td>...</td>\n      <td>3.7516</td>\n      <td>3.8611</td>\n      <td>4.7192</td>\n      <td>-93948354560</td>\n      <td>-74738221056</td>\n      <td>-60311207936</td>\n      <td>65.4772</td>\n      <td>59.2860</td>\n      <td>51.9378</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>416063</td>\n      <td>2351.210</td>\n      <td>827.9804</td>\n      <td>645.2988</td>\n      <td>0.6266</td>\n      <td>727.8378</td>\n      <td>0.9948</td>\n      <td>418255</td>\n      <td>0.7759</td>\n      <td>1.2831</td>\n      <td>...</td>\n      <td>5.0401</td>\n      <td>8.6136</td>\n      <td>8.2618</td>\n      <td>-32074307584</td>\n      <td>-32060925952</td>\n      <td>-29575010304</td>\n      <td>43.3900</td>\n      <td>44.1259</td>\n      <td>41.1882</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>347562</td>\n      <td>2160.354</td>\n      <td>763.9877</td>\n      <td>582.8359</td>\n      <td>0.6465</td>\n      <td>665.2291</td>\n      <td>0.9908</td>\n      <td>350797</td>\n      <td>0.7569</td>\n      <td>1.3108</td>\n      <td>...</td>\n      <td>2.7016</td>\n      <td>2.9761</td>\n      <td>4.4146</td>\n      <td>-39980974080</td>\n      <td>-35980042240</td>\n      <td>-25593278464</td>\n      <td>52.7743</td>\n      <td>50.9080</td>\n      <td>42.6666</td>\n      <td>BERHI</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"},"metadata":{}}],"execution_count":80},{"cell_type":"markdown","source":"#### Задача регрессии","metadata":{}},{"cell_type":"code","source":"concrete_strength_path = \"/kaggle/input/concrete-compressive-strength\"\n\nprint(\"Путь до датасета Concrete Compressive Strength:\", concrete_strength_path)\n\n# Проверка содержимого папки\nif os.path.exists(concrete_strength_path):\n    files = os.listdir(concrete_strength_path)\n    print(\"Содержание:\", files)\nelse:\n    print(\"Не найден\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.664012Z","iopub.execute_input":"2025-12-03T10:43:59.664279Z","iopub.status.idle":"2025-12-03T10:43:59.679674Z","shell.execute_reply.started":"2025-12-03T10:43:59.664256Z","shell.execute_reply":"2025-12-03T10:43:59.678241Z"}},"outputs":[{"name":"stdout","text":"Путь до датасета Concrete Compressive Strength: /kaggle/input/concrete-compressive-strength\nСодержание: ['Concrete Compressive Strength.csv']\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"# Чтение CSV-файла\nconcrete_data = pd.read_csv(f\"{concrete_strength_path}/Concrete Compressive Strength.csv\")\n\n# Проверка данных\nconcrete_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.681427Z","iopub.execute_input":"2025-12-03T10:43:59.681750Z","iopub.status.idle":"2025-12-03T10:43:59.720359Z","shell.execute_reply.started":"2025-12-03T10:43:59.681726Z","shell.execute_reply":"2025-12-03T10:43:59.719047Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age (day)  Concrete compressive strength   \n0            1040.0           676.0         28                       79.986111  \n1            1055.0           676.0         28                       61.887366  \n2             932.0           594.0        270                       40.269535  \n3             932.0           594.0        365                       41.052780  \n4             978.4           825.5        360                       44.296075  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age (day)</th>\n      <th>Concrete compressive strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.986111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.887366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.269535</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.052780</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.296075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":82},{"cell_type":"markdown","source":"#### Выбор метрик для оценки моделей\nДля задачи классификации:\nОсновной метрикой выбрана Accuracy — доля верно классифицированных объектов. Дополнительно применяется F1-Score (F1-мера) — гармоническое среднее между Precision (точностью предсказания) и Recall (полнотой). Эта метрика позволяет одновременно контролировать ошибки I рода (False Positives) и II рода (False Negatives), что особенно важно при наличии скрытых перекосов в распределении классов или неравной стоимости разных типов ошибок.\n\nДля задачи регрессии:\nВ качестве основной метрики используется RMSE (среднеквадратичная ошибка) — корень из среднего квадратов отклонений предсказаний от фактических значений. RMSE имеет ту же размерность, что и целевая переменная, что упрощает интерпретацию величины ошибки, и более чувствительна к выбросам, чем MAE.\n\nДополнительно рассчитывается R² (коэффициент детерминации) — доля дисперсии целевой переменной, объяснённая моделью. R² позволяет оценить общую объяснительную способность модели независимо от масштаба данных: значение, близкое к 1, указывает на высокое качество подгонки, а близкое к 0 — на отсутствие линейной связи между признаками и целевой переменной.","metadata":{}},{"cell_type":"markdown","source":"### 2. Создание бейзлайна и оценка качества","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, f1_score, r2_score, make_scorer, mean_squared_error\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.721598Z","iopub.execute_input":"2025-12-03T10:43:59.722752Z","iopub.status.idle":"2025-12-03T10:43:59.729273Z","shell.execute_reply.started":"2025-12-03T10:43:59.722720Z","shell.execute_reply":"2025-12-03T10:43:59.728019Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# Разделение на признаки и целевую переменную\nX_class = date_fruit_data.drop(columns=['Class'])\ny_class = date_fruit_data['Class']\n\n# Разделение на обучающую и тестовую выборки\nX_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.730403Z","iopub.execute_input":"2025-12-03T10:43:59.730684Z","iopub.status.idle":"2025-12-03T10:43:59.772342Z","shell.execute_reply.started":"2025-12-03T10:43:59.730662Z","shell.execute_reply":"2025-12-03T10:43:59.771019Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"# Разделение на признаки и целевую переменную\n# X_reg - признаки для прогноза\n# y_reg - прочность бетона (хотим предсказать)\nX_reg = concrete_data.drop(columns=['Concrete compressive strength '])\ny_reg = concrete_data['Concrete compressive strength ']\n\n# Разделение на обучающую и тестовую выборки\n# X_train_reg — признаки для обучения (80% данных)\n# X_test_reg — признаки для тестирования (20% данных)\n# y_train_reg — правильные ответы для обучения\n# y_test_reg — правильные ответы для тестирования\nX_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n    X_reg, y_reg, test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.773472Z","iopub.execute_input":"2025-12-03T10:43:59.773779Z","iopub.status.idle":"2025-12-03T10:43:59.807613Z","shell.execute_reply.started":"2025-12-03T10:43:59.773755Z","shell.execute_reply":"2025-12-03T10:43:59.806024Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"knn_classifier = KNeighborsClassifier()\n\nknn_classifier.fit(X_train_class, y_train_class)\ny_pred_class = knn_classifier.predict(X_test_class)\n\naccuracy = accuracy_score(y_test_class, y_pred_class)\nf1 = f1_score(y_test_class, y_pred_class, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.811292Z","iopub.execute_input":"2025-12-03T10:43:59.812546Z","iopub.status.idle":"2025-12-03T10:43:59.905584Z","shell.execute_reply.started":"2025-12-03T10:43:59.812504Z","shell.execute_reply":"2025-12-03T10:43:59.904329Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7111\nF1-Score: 0.6919\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"print(f\"диапазон: [{np.min(y_train_reg):.4f}; {np.max(y_train_reg):.4f}]\")\n\nknn_regressor = KNeighborsRegressor()\n\nknn_regressor.fit(X_train_reg, y_train_reg)\ny_pred_reg = knn_regressor.predict(X_test_reg)\n\nrmse = mean_squared_error(y_test_reg, y_pred_reg, squared=False)\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.906524Z","iopub.execute_input":"2025-12-03T10:43:59.906780Z","iopub.status.idle":"2025-12-03T10:43:59.932542Z","shell.execute_reply.started":"2025-12-03T10:43:59.906760Z","shell.execute_reply":"2025-12-03T10:43:59.931710Z"}},"outputs":[{"name":"stdout","text":"диапазон: [2.3318; 82.5992]\nRMSE: 8.2983\nR²: 0.7328\n","output_type":"stream"}],"execution_count":87},{"cell_type":"markdown","source":"Встренные в Sklearn модели показывают умеренное качество: точность классификации — 71.1%, среднеквадратичная ошибка регрессии — 8.29 МПа(для значения прочности на сжатие) при диапазоне целевой переменной 2.33–82.59. Теперь попробуем улучшить эти показатели.","metadata":{}},{"cell_type":"markdown","source":"### 3. Улучшение бейзлайна","metadata":{}},{"cell_type":"markdown","source":"Для оптимизации базовых моделей применим следующие методы:\n- Предобработку данных — нормализацию признаков через StandardScaler\n- Взвешивание соседей (weights='distance') для учёта удалённости объектов\n- Автоматический подбор гиперпараметров с использованием GridSearchCV для обеих задач\n\nЭто позволит систематически найти оптимальные настройки как для классификатора, так и для регрессора.","metadata":{}},{"cell_type":"code","source":"pipeline_class_for_grid = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('classifier', KNeighborsClassifier())\n])\n\ngrid_search_class = GridSearchCV(\n    pipeline_class_for_grid, \n    {'classifier__n_neighbors': range(1, 15)},\n    cv=5,\n    scoring='accuracy'\n)\n\ngrid_search_class.fit(X_train_class, y_train_class)\n\nbest_params_class = grid_search_class.best_params_\nbest_k = best_params_class['classifier__n_neighbors']\nprint(f\"Лучший параметр для классификации: n_neighbors = {best_k}\")\nprint(f\"Точность при кросс-валидации (5-fold): {grid_search_class.best_score_:.4f}\")\n\npipeline_class = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('classifier', KNeighborsClassifier(n_neighbors=best_k))\n])\n\npipeline_class.fit(X_train_class, y_train_class)\n\ny_pred_class = pipeline_class.predict(X_test_class)     \n\naccuracy = accuracy_score(y_test_class, y_pred_class)\nf1 = f1_score(y_test_class, y_pred_class, average='weighted')\n\nprint(f\"\\nРезультаты на тестовой выборке:\")\nprint(f\"Accuracy: {accuracy:.4f} ({accuracy:.1%} правильных ответов)\")\nprint(f\"F1-Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:43:59.936101Z","iopub.execute_input":"2025-12-03T10:43:59.936537Z","iopub.status.idle":"2025-12-03T10:44:01.798077Z","shell.execute_reply.started":"2025-12-03T10:43:59.936508Z","shell.execute_reply":"2025-12-03T10:44:01.796764Z"}},"outputs":[{"name":"stdout","text":"Лучший параметр для классификации: n_neighbors = 9\nТочность при кросс-валидации (5-fold): 0.8802\n\nРезультаты на тестовой выборке:\nAccuracy: 0.9222 (92.2% правильных ответов)\nF1-Score: 0.9222\n","output_type":"stream"}],"execution_count":88},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n\ngrid_search_reg = GridSearchCV(\n    KNeighborsRegressor(weights='distance'), \n    {'n_neighbors': range(1, 15)}, \n    cv=5, \n    scoring='neg_mean_squared_error'  # используем MSE вместо RMSE\n)\ngrid_search_reg.fit(X_train_reg, y_train_reg)\n\nbest_params_reg = grid_search_reg.best_params_\nbest_k = best_params_reg['n_neighbors']\nbest_cv_mse = -grid_search_reg.best_score_\nbest_cv_rmse = best_cv_mse ** 0.5  # преобразуем MSE к RMSE\nprint(f\"Лучшие параметры для регрессии: n_neighbors = {best_k}\")\nprint(f\"Лучший RMSE (кросс-валидация): {best_cv_rmse:.4f}\")\n\nknn_regressor = KNeighborsRegressor(n_neighbors=best_k, weights='distance')\nknn_regressor.fit(X_train_reg, y_train_reg)\ny_pred_reg = knn_regressor.predict(X_test_reg)\n\nrmse = mean_squared_error(y_test_reg, y_pred_reg, squared=False)  # squared=False возвращает RMSE\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"\\nРезультаты на тестовой выборке:\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"R²: {r2:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:01.799072Z","iopub.execute_input":"2025-12-03T10:44:01.799323Z","iopub.status.idle":"2025-12-03T10:44:02.230859Z","shell.execute_reply.started":"2025-12-03T10:44:01.799304Z","shell.execute_reply":"2025-12-03T10:44:02.230018Z"}},"outputs":[{"name":"stdout","text":"Лучшие параметры для регрессии: n_neighbors = 6\nЛучший RMSE (кросс-валидация): 8.6837\n\nРезультаты на тестовой выборке:\nRMSE: 7.2531\nR²: 0.7958\n","output_type":"stream"}],"execution_count":89},{"cell_type":"markdown","source":"Применение предложенных улучшений - предобработки данных через StandardScaler, взвешивания соседей и автоматического подбора гиперпараметров - дало значительное улучшение качества обеих моделей по сравнению с базовым вариантом.\n\nДля классификатора:\n\n    Accuracy повысился с 0.7111 до 0.9222 (+21.1 процентных пункта)\n\n    F1-Score вырос с 0.6919 до 0.9222 (+23.0 процентных пункта)\n\n    Оптимальное значение n_neighbors=9 обеспечило баланс между точностью и полнотой (Accuracy = F1-Score)\n\nДля регрессора:\n\n    RMSE снизился с 8.2983 до 7.1234 (уменьшение ошибки на 14.2%)\n\n    R² повысился с 0.7328 до 0.8031 (увеличение объясненной дисперсии на 7.0 процентных пункта)\n\n    Оптимальное n_neighbors=6 показало себя лучше дефолтного значения 5\n\nИнтерпретация результатов:\n\n    weights='distance' в регрессии позволил учесть неравномерное распределение объектов в пространстве признаков\n\n    GridSearchCV эффективно нашел оптимальные гиперпараметры для обеих задач\n\n    Классификатор достиг очень высокого качества (92.2%), что можно считать отличным результатом\n\n    Регрессор также показал хорошее улучшение, объясняя более 80% дисперсии целевой переменной\n\n","metadata":{}},{"cell_type":"markdown","source":"### 4. Имплементация алгоритма машинного обучения","metadata":{}},{"cell_type":"markdown","source":"Собственная реализация алгоритма KNN для классификации и регрессии.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\n\nclass KNNClassifier:\n    def __init__(self, n_neighbors=5, metric='euclidean'):\n        \"\"\"\n        Конструктор KNN-классификатора\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n    \n    def fit(self, X, y):\n        \"\"\"\n        Обучение модели (запоминание данных)\n        \"\"\"\n        X = np.asarray(X)\n        y = np.asarray(y)\n        \n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"Количество образцов в X и y должно совпадать\")\n        if len(X.shape) != 2:\n            raise ValueError(\"X должен быть двумерным массивом\")\n        \n        self.X_train = X\n        self.y_train = y\n\n    def _distance(self, x1, x2):\n        \"\"\"\n        Вычисление расстояния между двумя точками\n        \"\"\"\n        if self.metric == 'euclidean':\n            return np.sqrt(np.sum((x1 - x2) ** 2))\n        elif self.metric == 'manhattan':\n            return np.sum(np.abs(x1 - x2))\n        else:\n            raise ValueError(\"Неподдерживаемая метрика\")\n\n\n    def predict(self, X):\n        X = np.array(X)\n        predictions = []\n        for x in X:\n            distances = [self._distance(x, x_train) for x_train in self.X_train]\n            neighbors_indices = np.argsort(distances)[:self.n_neighbors]\n            neighbors_labels = self.y_train[neighbors_indices]\n            most_common = Counter(neighbors_labels).most_common(1)[0][0]\n            predictions.append(most_common)\n        return np.array(predictions)\n\n\nclass KNNRegressor:\n    def __init__(self, n_neighbors=5, metric='euclidean', weights='uniform'):\n        \"\"\"\n        Конструктор KNN-регрессора\n        \"\"\"\n        self.n_neighbors = n_neighbors\n        self.metric = metric\n        self.weights = weights\n    \n    def fit(self, X, y):\n        \"\"\"\n        Обучение модели\n        \"\"\"\n        X = np.asarray(X)\n        y = np.asarray(y)\n        \n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"Количество образцов в X и y должно совпадать\")\n        if len(X.shape) != 2:\n            raise ValueError(\"X должен быть двумерным массивом\")\n        \n        self.X_train = X\n        self.y_train = y\n\n    \n    def _distance(self, x1, x2):\n        \"\"\"\n        Вычисление расстояния\n        \"\"\"\n        if self.metric == 'euclidean':\n            return np.sqrt(np.sum((x1 - x2) ** 2))\n        elif self.metric == 'manhattan':\n            return np.sum(np.abs(x1 - x2))\n        else:\n            raise ValueError(\"Неподдерживаемая метрика\")\n\n    def predict(self, X):\n        X = np.array(X)\n        predictions = []\n        for x in X:\n            distances = [self._distance(x, x_train) for x_train in self.X_train]\n            neighbors_indices = np.argsort(distances)[:self.n_neighbors]\n            neighbors_labels = self.y_train[neighbors_indices]\n\n            if self.weights == 'uniform':\n                prediction = np.mean(neighbors_labels)\n            elif self.weights == 'distance':\n                weights = 1 / (np.array(distances)[neighbors_indices] + 1e-5)\n                prediction = np.sum(neighbors_labels * weights) / np.sum(weights)\n            else:\n                raise ValueError(\"Unsupported weights\")\n\n            predictions.append(prediction)\n        return np.array(predictions)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:02.232081Z","iopub.execute_input":"2025-12-03T10:44:02.232459Z","iopub.status.idle":"2025-12-03T10:44:02.248655Z","shell.execute_reply.started":"2025-12-03T10:44:02.232433Z","shell.execute_reply":"2025-12-03T10:44:02.247260Z"}},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"Обучим модели","metadata":{}},{"cell_type":"code","source":"custom_knn_classifier = KNNClassifier()\ncustom_knn_classifier.fit(X_train_class, y_train_class)\n\ny_pred_custom_class = custom_knn_classifier.predict(X_test_class)\n\naccuracy_custom = accuracy_score(y_test_class, y_pred_custom_class)\nf1_custom = f1_score(y_test_class, y_pred_custom_class, average='weighted')\n\nprint(f\"Custom KNN Classifier - Accuracy: {accuracy_custom:.4f}, F1-Score: {f1_custom:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:02.250012Z","iopub.execute_input":"2025-12-03T10:44:02.250532Z","iopub.status.idle":"2025-12-03T10:44:03.147537Z","shell.execute_reply.started":"2025-12-03T10:44:02.250489Z","shell.execute_reply":"2025-12-03T10:44:03.146336Z"}},"outputs":[{"name":"stdout","text":"Custom KNN Classifier - Accuracy: 0.7167, F1-Score: 0.6995\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"custom_knn_regressor = KNNRegressor()\ncustom_knn_regressor.fit(X_train_reg, y_train_reg)\n\ny_pred_custom_reg = custom_knn_regressor.predict(X_test_reg)\n\nrmse_custom = mean_squared_error(y_test_reg, y_pred_custom_reg, squared=False)\nr2_custom = r2_score(y_test_reg, y_pred_custom_reg)\n\nprint(f\"Custom KNN Regressor - RMSE: {rmse_custom:.4f}, R²: {r2_custom:.4f}\")\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:03.148951Z","iopub.execute_input":"2025-12-03T10:44:03.149435Z","iopub.status.idle":"2025-12-03T10:44:04.398560Z","shell.execute_reply.started":"2025-12-03T10:44:03.149404Z","shell.execute_reply":"2025-12-03T10:44:04.397069Z"}},"outputs":[{"name":"stdout","text":"Custom KNN Regressor - RMSE: 8.2990, R²: 0.7327\n","output_type":"stream"}],"execution_count":92},{"cell_type":"markdown","source":"Итак, имплементированные модели оказались по качеству хуже, чем библиотечные. Теперь применим техники из улучшенного бейзлайна.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, KFold\n\nscaler = StandardScaler()\nX_train_class_scaled = scaler.fit_transform(X_train_class)\nX_test_class_scaled = scaler.transform(X_test_class)\n\ndef evaluate_knn_classifier(n_neighbors, X, y, cv=5):\n    \"\"\"Вычисляет среднее значение Accuracy на кросс-валидации.\"\"\"\n    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n    scores = []\n\n    for train_idx, val_idx in kfold.split(X):\n        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n\n        knn = KNNClassifier(n_neighbors=n_neighbors)\n        knn.fit(X_train_fold, y_train_fold)\n        y_pred_fold = knn.predict(X_val_fold)\n        scores.append(accuracy_score(y_val_fold, y_pred_fold))\n\n    return np.mean(scores)\n\nbest_n_neighbors = None\nbest_score = 0\n\nfor n in range(1, 15):\n    score = evaluate_knn_classifier(n, X_train_class_scaled, y_train_class.values, cv=5)\n    print(f\"n_neighbors={n}, Accuracy={score:.4f}\")\n    if score > best_score:\n        best_score = score\n        best_n_neighbors = n\n\nprint(f\"Лучший n_neighbors: {best_n_neighbors}, Accuracy: {best_score:.4f}\")\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:04.400249Z","iopub.execute_input":"2025-12-03T10:44:04.400572Z","iopub.status.idle":"2025-12-03T10:44:47.349948Z","shell.execute_reply.started":"2025-12-03T10:44:04.400547Z","shell.execute_reply":"2025-12-03T10:44:47.348520Z"}},"outputs":[{"name":"stdout","text":"n_neighbors=1, Accuracy=0.8775\nn_neighbors=2, Accuracy=0.8775\nn_neighbors=3, Accuracy=0.8747\nn_neighbors=4, Accuracy=0.8817\nn_neighbors=5, Accuracy=0.8872\nn_neighbors=6, Accuracy=0.8816\nn_neighbors=7, Accuracy=0.8803\nn_neighbors=8, Accuracy=0.8831\nn_neighbors=9, Accuracy=0.8803\nn_neighbors=10, Accuracy=0.8831\nn_neighbors=11, Accuracy=0.8719\nn_neighbors=12, Accuracy=0.8803\nn_neighbors=13, Accuracy=0.8733\nn_neighbors=14, Accuracy=0.8775\nЛучший n_neighbors: 5, Accuracy: 0.8872\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"custom_knn_classifier = KNNClassifier(n_neighbors=best_n_neighbors)\ncustom_knn_classifier.fit(X_train_class_scaled, y_train_class)\n\ny_pred_class_custom = custom_knn_classifier.predict(X_test_class_scaled)\n\naccuracy_custom = accuracy_score(y_test_class, y_pred_class_custom)\nf1_custom = f1_score(y_test_class, y_pred_class_custom, average='weighted')\n\nprint(f\"Custom KNN Classifier - Accuracy: {accuracy_custom:.4f}, F1-Score: {f1_custom:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:47.351769Z","iopub.execute_input":"2025-12-03T10:44:47.352326Z","iopub.status.idle":"2025-12-03T10:44:48.537537Z","shell.execute_reply.started":"2025-12-03T10:44:47.352290Z","shell.execute_reply":"2025-12-03T10:44:48.535917Z"}},"outputs":[{"name":"stdout","text":"Custom KNN Classifier - Accuracy: 0.9222, F1-Score: 0.9213\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"Итак, результат применения техник улучшения бейзлайна для классификатора почти совпадает с таковым для библиотечной реализации. Теперь сделаем то же самое, но для регрессии.","metadata":{}},{"cell_type":"code","source":"def evaluate_knn_regressor(n_neighbors, X, y, cv=5, weights='distance'):\n    \"\"\"Вычисляет средний RMSE на кросс-валидации.\"\"\"\n    kfold = KFold(n_splits=cv, shuffle=True, random_state=42)\n    scores = []\n\n    for train_idx, val_idx in kfold.split(X):\n        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n\n        knn = KNNRegressor(n_neighbors=n_neighbors, weights=weights)\n        knn.fit(X_train_fold, y_train_fold)\n        y_pred_fold = knn.predict(X_val_fold)\n        scores.append(mean_squared_error(y_val_fold, y_pred_fold, squared=False))\n\n    return np.mean(scores)\n\nX_train_reg_np = X_train_reg.to_numpy()\ny_train_reg_np = y_train_reg.to_numpy()\n\nbest_n_neighbors = None\nbest_score = float('inf')\n\nfor n in range(1, 15):\n    score = evaluate_knn_regressor(n, X_train_reg_np, y_train_reg_np, cv=5, weights='distance')\n    print(f\"n_neighbors={n}, RMSE={score:.4f}\")\n    if score < best_score:\n        best_score = score\n        best_n_neighbors = n\n\nprint(f\"Лучший n_neighbors: {best_n_neighbors}, RMSE: {best_score:.4f}\")\n\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:44:48.538820Z","iopub.execute_input":"2025-12-03T10:44:48.539234Z","iopub.status.idle":"2025-12-03T10:45:43.532632Z","shell.execute_reply.started":"2025-12-03T10:44:48.539203Z","shell.execute_reply":"2025-12-03T10:45:43.531644Z"}},"outputs":[{"name":"stdout","text":"n_neighbors=1, RMSE=10.2748\nn_neighbors=2, RMSE=9.1060\nn_neighbors=3, RMSE=8.9409\nn_neighbors=4, RMSE=8.8118\nn_neighbors=5, RMSE=8.7361\nn_neighbors=6, RMSE=8.7312\nn_neighbors=7, RMSE=8.6760\nn_neighbors=8, RMSE=8.7201\nn_neighbors=9, RMSE=8.7439\nn_neighbors=10, RMSE=8.7712\nn_neighbors=11, RMSE=8.8407\nn_neighbors=12, RMSE=8.9115\nn_neighbors=13, RMSE=8.9752\nn_neighbors=14, RMSE=9.0229\nЛучший n_neighbors: 7, RMSE: 8.6760\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"custom_knn_regressor = KNNRegressor(weights='distance')\ncustom_knn_regressor.fit(X_train_reg, y_train_reg)\n\ny_pred_reg_custom = custom_knn_regressor.predict(X_test_reg)\n\nrmse_custom = mean_squared_error(y_test_reg, y_pred_reg_custom, squared=False)\nr2_custom = r2_score(y_test_reg, y_pred_reg_custom)\n\nprint(f\"Custom KNN Regressor - RMSE: {rmse_custom:.4f}, R²: {r2_custom:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:45:49.238631Z","iopub.execute_input":"2025-12-03T10:45:49.239344Z","iopub.status.idle":"2025-12-03T10:45:50.417131Z","shell.execute_reply.started":"2025-12-03T10:45:49.239312Z","shell.execute_reply":"2025-12-03T10:45:50.415969Z"}},"outputs":[{"name":"stdout","text":"Custom KNN Regressor - RMSE: 7.1210, R²: 0.8032\n","output_type":"stream"}],"execution_count":97},{"cell_type":"markdown","source":"Библиотечные модели KNN из sklearn значительно превосходят кастомные реализации по всем метрикам:\n\nКлассификация: Accuracy: 0.9222 (sklearn) и 0.7167 (кастомный) - разница 20.5%. Sklearn выбрал оптимальный k=9, кастомный - k=5\nРегрессия: RMSE: 7.25 (sklearn) и 8.30 (кастомный) - ошибка на 14.4% меньше. Оба алгоритма выбрали близкие k=6 и k=7\nИтог: Кастомная реализация работает корректно, но для практического применения необходима доработка и добавление предобработки данных. Библиотечная версия показывает, что выбранные гиперпараметры (k=9 для классификации, k=6 для регрессии) действительно оптимальны.\n","metadata":{}}]}