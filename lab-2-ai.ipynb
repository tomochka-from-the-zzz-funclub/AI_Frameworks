{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3400552,"sourceType":"datasetVersion","datasetId":2049845},{"sourceId":7963387,"sourceType":"datasetVersion","datasetId":1328826}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Лабораторная работа №2: Проведение исследований с логистической и линейной регрессией","metadata":{}},{"cell_type":"markdown","source":"### 1. Выбор начальных условий","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn numpy pandas matplotlib seaborn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:11.215717Z","iopub.execute_input":"2025-12-14T19:59:11.216108Z","iopub.status.idle":"2025-12-14T19:59:17.076122Z","shell.execute_reply.started":"2025-12-14T19:59:11.216084Z","shell.execute_reply":"2025-12-14T19:59:17.074791Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:17.078651Z","iopub.execute_input":"2025-12-14T19:59:17.079101Z","iopub.status.idle":"2025-12-14T19:59:18.445523Z","shell.execute_reply.started":"2025-12-14T19:59:17.079059Z","shell.execute_reply":"2025-12-14T19:59:18.444733Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"date_fruit_path = \"/kaggle/input/date-fruit-datasets\"\n\nprint(\"Path to Date Fruit dataset files:\", date_fruit_path)\n\n# Проверка содержимого папки\nif os.path.exists(date_fruit_path):\n    files = os.listdir(date_fruit_path)\n    print(\"Files:\", files)\nelse:\n    print(\"Not found\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:18.446446Z","iopub.execute_input":"2025-12-14T19:59:18.446942Z","iopub.status.idle":"2025-12-14T19:59:18.460153Z","shell.execute_reply.started":"2025-12-14T19:59:18.446918Z","shell.execute_reply":"2025-12-14T19:59:18.458739Z"}},"outputs":[{"name":"stdout","text":"Path to Date Fruit dataset files: /kaggle/input/date-fruit-datasets\nFiles: ['Date_Fruit_Datasets']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Чтение Excel-файла\ndate_fruit_data = pd.read_excel(f\"{date_fruit_path}/Date_Fruit_Datasets/Date_Fruit_Datasets.xlsx\")\n\n# Проверка данных\ndate_fruit_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:18.461874Z","iopub.execute_input":"2025-12-14T19:59:18.462204Z","iopub.status.idle":"2025-12-14T19:59:19.584773Z","shell.execute_reply.started":"2025-12-14T19:59:18.462171Z","shell.execute_reply":"2025-12-14T19:59:19.583849Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"     AREA  PERIMETER  MAJOR_AXIS  MINOR_AXIS  ECCENTRICITY   EQDIASQ  \\\n0  422163   2378.908    837.8484    645.6693        0.6373  733.1539   \n1  338136   2085.144    723.8198    595.2073        0.5690  656.1464   \n2  526843   2647.394    940.7379    715.3638        0.6494  819.0222   \n3  416063   2351.210    827.9804    645.2988        0.6266  727.8378   \n4  347562   2160.354    763.9877    582.8359        0.6465  665.2291   \n\n   SOLIDITY  CONVEX_AREA  EXTENT  ASPECT_RATIO  ...  KurtosisRR  KurtosisRG  \\\n0    0.9947       424428  0.7831        1.2976  ...      3.2370      2.9574   \n1    0.9974       339014  0.7795        1.2161  ...      2.6228      2.6350   \n2    0.9962       528876  0.7657        1.3150  ...      3.7516      3.8611   \n3    0.9948       418255  0.7759        1.2831  ...      5.0401      8.6136   \n4    0.9908       350797  0.7569        1.3108  ...      2.7016      2.9761   \n\n   KurtosisRB    EntropyRR    EntropyRG    EntropyRB  ALLdaub4RR  ALLdaub4RG  \\\n0      4.2287 -59191263232 -50714214400 -39922372608     58.7255     54.9554   \n1      3.1704 -34233065472 -37462601728 -31477794816     50.0259     52.8168   \n2      4.7192 -93948354560 -74738221056 -60311207936     65.4772     59.2860   \n3      8.2618 -32074307584 -32060925952 -29575010304     43.3900     44.1259   \n4      4.4146 -39980974080 -35980042240 -25593278464     52.7743     50.9080   \n\n   ALLdaub4RB  Class  \n0     47.8400  BERHI  \n1     47.8315  BERHI  \n2     51.9378  BERHI  \n3     41.1882  BERHI  \n4     42.6666  BERHI  \n\n[5 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AREA</th>\n      <th>PERIMETER</th>\n      <th>MAJOR_AXIS</th>\n      <th>MINOR_AXIS</th>\n      <th>ECCENTRICITY</th>\n      <th>EQDIASQ</th>\n      <th>SOLIDITY</th>\n      <th>CONVEX_AREA</th>\n      <th>EXTENT</th>\n      <th>ASPECT_RATIO</th>\n      <th>...</th>\n      <th>KurtosisRR</th>\n      <th>KurtosisRG</th>\n      <th>KurtosisRB</th>\n      <th>EntropyRR</th>\n      <th>EntropyRG</th>\n      <th>EntropyRB</th>\n      <th>ALLdaub4RR</th>\n      <th>ALLdaub4RG</th>\n      <th>ALLdaub4RB</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>422163</td>\n      <td>2378.908</td>\n      <td>837.8484</td>\n      <td>645.6693</td>\n      <td>0.6373</td>\n      <td>733.1539</td>\n      <td>0.9947</td>\n      <td>424428</td>\n      <td>0.7831</td>\n      <td>1.2976</td>\n      <td>...</td>\n      <td>3.2370</td>\n      <td>2.9574</td>\n      <td>4.2287</td>\n      <td>-59191263232</td>\n      <td>-50714214400</td>\n      <td>-39922372608</td>\n      <td>58.7255</td>\n      <td>54.9554</td>\n      <td>47.8400</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>338136</td>\n      <td>2085.144</td>\n      <td>723.8198</td>\n      <td>595.2073</td>\n      <td>0.5690</td>\n      <td>656.1464</td>\n      <td>0.9974</td>\n      <td>339014</td>\n      <td>0.7795</td>\n      <td>1.2161</td>\n      <td>...</td>\n      <td>2.6228</td>\n      <td>2.6350</td>\n      <td>3.1704</td>\n      <td>-34233065472</td>\n      <td>-37462601728</td>\n      <td>-31477794816</td>\n      <td>50.0259</td>\n      <td>52.8168</td>\n      <td>47.8315</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>526843</td>\n      <td>2647.394</td>\n      <td>940.7379</td>\n      <td>715.3638</td>\n      <td>0.6494</td>\n      <td>819.0222</td>\n      <td>0.9962</td>\n      <td>528876</td>\n      <td>0.7657</td>\n      <td>1.3150</td>\n      <td>...</td>\n      <td>3.7516</td>\n      <td>3.8611</td>\n      <td>4.7192</td>\n      <td>-93948354560</td>\n      <td>-74738221056</td>\n      <td>-60311207936</td>\n      <td>65.4772</td>\n      <td>59.2860</td>\n      <td>51.9378</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>416063</td>\n      <td>2351.210</td>\n      <td>827.9804</td>\n      <td>645.2988</td>\n      <td>0.6266</td>\n      <td>727.8378</td>\n      <td>0.9948</td>\n      <td>418255</td>\n      <td>0.7759</td>\n      <td>1.2831</td>\n      <td>...</td>\n      <td>5.0401</td>\n      <td>8.6136</td>\n      <td>8.2618</td>\n      <td>-32074307584</td>\n      <td>-32060925952</td>\n      <td>-29575010304</td>\n      <td>43.3900</td>\n      <td>44.1259</td>\n      <td>41.1882</td>\n      <td>BERHI</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>347562</td>\n      <td>2160.354</td>\n      <td>763.9877</td>\n      <td>582.8359</td>\n      <td>0.6465</td>\n      <td>665.2291</td>\n      <td>0.9908</td>\n      <td>350797</td>\n      <td>0.7569</td>\n      <td>1.3108</td>\n      <td>...</td>\n      <td>2.7016</td>\n      <td>2.9761</td>\n      <td>4.4146</td>\n      <td>-39980974080</td>\n      <td>-35980042240</td>\n      <td>-25593278464</td>\n      <td>52.7743</td>\n      <td>50.9080</td>\n      <td>42.6666</td>\n      <td>BERHI</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"concrete_strength_path = \"/kaggle/input/concrete-compressive-strength\"\n\nprint(\"Путь до датасета Concrete Compressive Strength:\", concrete_strength_path)\n\n# Проверка содержимого папки\nif os.path.exists(concrete_strength_path):\n    files = os.listdir(concrete_strength_path)\n    print(\"Содержание:\", files)\nelse:\n    print(\"Не найден\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:19.587318Z","iopub.execute_input":"2025-12-14T19:59:19.587688Z","iopub.status.idle":"2025-12-14T19:59:19.599952Z","shell.execute_reply.started":"2025-12-14T19:59:19.587668Z","shell.execute_reply":"2025-12-14T19:59:19.598737Z"}},"outputs":[{"name":"stdout","text":"Путь до датасета Concrete Compressive Strength: /kaggle/input/concrete-compressive-strength\nСодержание: ['Concrete Compressive Strength.csv']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Чтение CSV-файла\nconcrete_data = pd.read_csv(f\"{concrete_strength_path}/Concrete Compressive Strength.csv\")\n\n# Проверка данных\nconcrete_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:19.601243Z","iopub.execute_input":"2025-12-14T19:59:19.601537Z","iopub.status.idle":"2025-12-14T19:59:19.637107Z","shell.execute_reply.started":"2025-12-14T19:59:19.601515Z","shell.execute_reply":"2025-12-14T19:59:19.636219Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age (day)  Concrete compressive strength   \n0            1040.0           676.0         28                       79.986111  \n1            1055.0           676.0         28                       61.887366  \n2             932.0           594.0        270                       40.269535  \n3             932.0           594.0        365                       41.052780  \n4             978.4           825.5        360                       44.296075  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age (day)</th>\n      <th>Concrete compressive strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.986111</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.887366</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.269535</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.052780</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.296075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### 2. Создание бейзлайна и оценка качества","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score, make_scorer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:19.638014Z","iopub.execute_input":"2025-12-14T19:59:19.638284Z","iopub.status.idle":"2025-12-14T19:59:19.950738Z","shell.execute_reply.started":"2025-12-14T19:59:19.638251Z","shell.execute_reply":"2025-12-14T19:59:19.949961Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Разделим датасет для классификации на обучающую и тестовую выборки","metadata":{}},{"cell_type":"code","source":"# Разделение на признаки и целевую переменную\nX_class = date_fruit_data.drop(columns=['Class'])\ny_class = date_fruit_data['Class']\n\n# Разделение на обучающую и тестовую выборки\nX_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n)\n\n# Преобразование целевой переменной\nlabel_encoder = LabelEncoder()\ny_train_class = label_encoder.fit_transform(y_train_class)\ny_test_class = label_encoder.transform(y_test_class)\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:19.951680Z","iopub.execute_input":"2025-12-14T19:59:19.952008Z","iopub.status.idle":"2025-12-14T19:59:19.969934Z","shell.execute_reply.started":"2025-12-14T19:59:19.951975Z","shell.execute_reply":"2025-12-14T19:59:19.969031Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Аналогично разделим датасет для регрессии","metadata":{}},{"cell_type":"code","source":"# Разделение на признаки и целевую переменную\nX_reg = concrete_data.drop(columns=['Concrete compressive strength '])\ny_reg = concrete_data['Concrete compressive strength ']\n\n# Разделение на обучающую и тестовую выборки\nX_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n    X_reg, y_reg, test_size=0.2, random_state=42\n)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:19.970805Z","iopub.execute_input":"2025-12-14T19:59:19.971047Z","iopub.status.idle":"2025-12-14T19:59:19.994386Z","shell.execute_reply.started":"2025-12-14T19:59:19.971029Z","shell.execute_reply":"2025-12-14T19:59:19.993362Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Обучим модели для классификации и регрессии из Sklearn и оценим их. Для логистической регрессии нам требуется обязательный препроцессинг данных с помощью StandardScaler.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_class = scaler.fit_transform(X_train_class)\nX_test_class = scaler.transform(X_test_class)\n\nlogistic = LogisticRegression(max_iter=10000)\nlogistic.fit(X_train_class, y_train_class)\n\ny_pred_class = logistic.predict(X_test_class)\n\naccuracy = accuracy_score(y_test_class, y_pred_class)\nf1 = f1_score(y_test_class, y_pred_class, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:19.995781Z","iopub.execute_input":"2025-12-14T19:59:19.996071Z","iopub.status.idle":"2025-12-14T19:59:20.545402Z","shell.execute_reply.started":"2025-12-14T19:59:19.996050Z","shell.execute_reply":"2025-12-14T19:59:20.544386Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9278\nF1-Score: 0.9263\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"linear_regressor = LinearRegression()\nlinear_regressor.fit(X_train_reg, y_train_reg)\n\ny_pred_reg = linear_regressor.predict(X_test_reg)\n\nrmse = mean_squared_error(y_test_reg, y_pred_reg, squared=False)\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"R²: {r2:.4f}\")\n     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:20.546136Z","iopub.execute_input":"2025-12-14T19:59:20.546379Z","iopub.status.idle":"2025-12-14T19:59:20.578054Z","shell.execute_reply.started":"2025-12-14T19:59:20.546358Z","shell.execute_reply":"2025-12-14T19:59:20.577329Z"}},"outputs":[{"name":"stdout","text":"RMSE: 9.7967\nR²: 0.6275\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Итак, точность для встроенной в Sklearn модели логистической регрессии получилась отличной (92.7% точности). Для модели линейной регрессии среднеквадратичная ошибка составила 9.79, что несколько хуже бейзлайна для KNN-регрессора. Попробуем улучшить бейзлайн.","metadata":{}},{"cell_type":"markdown","source":"### 3. Улучшение бейзлайна\n\nДля улучшения бейзлайна для логистичекой регрессии будем подбирать гиперпараметр C с помощью GridSearchCV. Для линейной регрессии добавим регуляризацию через Ridge (L2).","metadata":{}},{"cell_type":"code","source":"\n\n# Пайплайн с нормализацией и логистической регрессией\npipeline_logistic = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('logistic', LogisticRegression(max_iter=10000, random_state=42))\n])\n\n# Параметры для подбора\nparam_grid_logistic = {\n    'logistic__C': [0.01, 0.1, 1, 10, 75, 1000],\n    'logistic__penalty': ['l2'],\n    'logistic__solver': ['lbfgs']\n}\n\n# Подбор гиперпараметров\ngrid_search_logistic = GridSearchCV(\n    pipeline_logistic,\n    param_grid_logistic,\n    cv=5,\n    scoring='accuracy',\n    verbose=1,\n    n_jobs=-1\n)\n\ngrid_search_logistic.fit(X_train_class, y_train_class)\n\nbest_params_logistic = grid_search_logistic.best_params_\nbest_score_logistic = grid_search_logistic.best_score_\n\nprint(\"\\n\" + \"=\"*50)\nprint(f\"Лучшие параметры для Logistic Regression: {best_params_logistic}\")\nprint(f\"Лучший Accuracy на кросс-валидации: {best_score_logistic:.4f}\")\n\n# Оценка на тестовой выборке\ny_pred_class = grid_search_logistic.best_estimator_.predict(X_test_class)\naccuracy = accuracy_score(y_test_class, y_pred_class)\nf1 = f1_score(y_test_class, y_pred_class, average='weighted')\n\nprint(f\"Test Accuracy: {accuracy:.4f}\")\nprint(f\"Test F1-Score: {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:20.579143Z","iopub.execute_input":"2025-12-14T19:59:20.579405Z","iopub.status.idle":"2025-12-14T19:59:24.732166Z","shell.execute_reply.started":"2025-12-14T19:59:20.579384Z","shell.execute_reply":"2025-12-14T19:59:24.728135Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 6 candidates, totalling 30 fits\n\n==================================================\nЛучшие параметры для Logistic Regression: {'logistic__C': 1, 'logistic__penalty': 'l2', 'logistic__solver': 'lbfgs'}\nЛучший Accuracy на кросс-валидации: 0.9150\nTest Accuracy: 0.9278\nTest F1-Score: 0.9263\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"param_grid_ridge = {\n    'alpha': [0.001, 0.01, 0.1, 1, 5, 10, 50, 100, 500, 1000, 5000]  \n}\n\ngrid_search_ridge = GridSearchCV(\n    Ridge(random_state=42), \n    param_grid_ridge,\n    cv=5,\n    scoring=['neg_root_mean_squared_error', 'r2'],  \n    refit='neg_root_mean_squared_error',  \n    verbose=1,\n    n_jobs=-1 \n)\n\ngrid_search_ridge.fit(X_train_reg, y_train_reg)\n\nbest_params_ridge = grid_search_ridge.best_params_\nbest_rmse_score = -grid_search_ridge.best_score_ \n\ncv_results = grid_search_ridge.cv_results_\n\nprint(f\"Лучшие параметры для Ridge Regression: {best_params_ridge}\")\nprint(f\"Лучший RMSE на кросс-валидации: {best_rmse_score:.4f}\")\n\nbest_idx = grid_search_ridge.best_index_\nprint(f\"Лучшее alpha: {best_params_ridge['alpha']}\")\nprint(f\"Соответствующий R² на кросс-валидации: {cv_results['mean_test_r2'][best_idx]:.4f}\")\n\n# Оценка на тестовой выборке\nridge_regressor = grid_search_ridge.best_estimator_\ny_pred_reg = ridge_regressor.predict(X_test_reg)\n\nrmse = mean_squared_error(y_test_reg, y_pred_reg, squared=False)\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"\\nРезультаты на тестовой выборке:\")\nprint(f\"Test RMSE: {rmse:.4f}\")\nprint(f\"Test R²:   {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:24.733515Z","iopub.execute_input":"2025-12-14T19:59:24.733876Z","iopub.status.idle":"2025-12-14T19:59:25.447808Z","shell.execute_reply.started":"2025-12-14T19:59:24.733849Z","shell.execute_reply":"2025-12-14T19:59:25.446807Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 11 candidates, totalling 55 fits\nЛучшие параметры для Ridge Regression: {'alpha': 5000}\nЛучший RMSE на кросс-валидации: 10.6490\nЛучшее alpha: 5000\nСоответствующий R² на кросс-валидации: 0.5957\n\nРезультаты на тестовой выборке:\nTest RMSE: 9.7956\nTest R²:   0.6276\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Итак, результаты лишь немного улучшились по сравнению с бейзлайном.","metadata":{}},{"cell_type":"markdown","source":"### 4. Имплементация алгоритма машинного обучения\nНапишем собственную реализацию Logistic and Linear regression, затем обучим модели на тестовых данных и сравним по качеству с реализациями из Sklearn.","metadata":{}},{"cell_type":"code","source":"sigmoid_function = lambda z: np.clip(1 / (1 + np.exp(-np.clip(z, -500, 500))), 1e-10, 1 - 1e-10)\n\ndef optimize_gradients(gradient_fn, start_point, learning_rate, max_iter, tolerance=1e-6):\n    current_point = start_point\n    for i in range(max_iter):\n        grad = gradient_fn(current_point)\n        current_point -= learning_rate * grad\n        \n        if np.linalg.norm(grad) < tolerance:\n            print(f\"Градиент сошелся на итерации {i}\")\n            break\n    return current_point\n\n\nclass CustomLogisticRegression:\n    def __init__(self, *, lr=0.01, max_epochs=1000, add_intercept=True):\n        self._learning_rate = lr\n        self._max_epochs = max_epochs\n        self._add_intercept = add_intercept\n        self._parameters = None\n        self._X_train = None\n        self._y_train = None\n        self._X_train_mean = None\n        self._X_train_std = None\n\n    def _add_intercept_to_X(self, X):\n        if self._add_intercept:\n            return np.hstack([np.ones((X.shape[0], 1)), X])\n        return X\n\n    def _compute_gradient(self, params):\n        assert self._X_train is not None\n        assert self._y_train is not None\n\n        samples = self._X_train.shape[0]\n        predictions = sigmoid_function(np.dot(self._X_train, params))\n        \n        grad = np.dot(self._X_train.T, (predictions - self._y_train)) / samples\n        return grad\n\n    def fit(self, X, y):\n        assert self._parameters is None\n\n        X_array = np.array(X)\n        y_array = np.array(y).reshape(-1, 1)\n        \n        # Нормализация признаков для стабильности\n        if X_array.shape[1] > 0:\n            self._X_train_mean = np.mean(X_array, axis=0)\n            self._X_train_std = np.std(X_array, axis=0) + 1e-8\n            X_normalized = (X_array - self._X_train_mean) / self._X_train_std\n            self._X_train = self._add_intercept_to_X(X_normalized)\n        else:\n            self._X_train = self._add_intercept_to_X(X_array)\n        \n        self._y_train = y_array\n        features = self._X_train.shape[1]\n        \n        initial_params = np.zeros((features, 1))\n        \n        self._parameters = optimize_gradients(\n            self._compute_gradient, \n            initial_params, \n            self._learning_rate, \n            self._max_epochs\n        ).flatten()\n\n    def predict_proba(self, X):\n        assert self._parameters is not None\n        \n        X_array = np.array(X)\n        \n        # Применяем ту же нормализацию, что при обучении\n        if self._X_train_mean is not None:\n            X_normalized = (X_array - self._X_train_mean) / self._X_train_std\n            X_with_intercept = self._add_intercept_to_X(X_normalized)\n        else:\n            X_with_intercept = self._add_intercept_to_X(X_array)\n            \n        z = np.dot(X_with_intercept, self._parameters)\n        return sigmoid_function(z)\n\n    def predict(self, X, threshold=0.5):\n        probabilities = self.predict_proba(X)\n        return (probabilities >= threshold).astype(int)\n\n\nclass CustomLinearRegression:\n    def __init__(self, add_intercept=True):\n        self._add_intercept = add_intercept\n        self._coef_ = None\n        self._X_mean = None\n        self._X_std = None\n\n    def _add_intercept_to_X(self, X):\n        if self._add_intercept:\n            return np.hstack([np.ones((X.shape[0], 1)), X])\n        return X\n\n    def fit(self, X, y):\n        X_array = np.array(X)\n        y_array = np.array(y).reshape(-1, 1)\n        \n        # Нормализация признаков\n        if X_array.shape[1] > 0:\n            self._X_mean = np.mean(X_array, axis=0)\n            self._X_std = np.std(X_array, axis=0) + 1e-8\n            X_normalized = (X_array - self._X_mean) / self._X_std\n            X_intercept = self._add_intercept_to_X(X_normalized)\n        else:\n            X_intercept = self._add_intercept_to_X(X_array)\n        \n        self._coef_ = np.linalg.pinv(X_intercept) @ y_array\n        \n        return self\n\n    def predict(self, X):\n        X_array = np.array(X)\n        \n        # Применяем нормализацию\n        if self._X_mean is not None:\n            X_normalized = (X_array - self._X_mean) / self._X_std\n            X_intercept = self._add_intercept_to_X(X_normalized)\n        else:\n            X_intercept = self._add_intercept_to_X(X_array)\n            \n        return (X_intercept @ self._coef_).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:25.450226Z","iopub.execute_input":"2025-12-14T19:59:25.450493Z","iopub.status.idle":"2025-12-14T19:59:25.471915Z","shell.execute_reply.started":"2025-12-14T19:59:25.450474Z","shell.execute_reply":"2025-12-14T19:59:25.471019Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"Обучим модели и оценим их качество","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score\n\nlog_reg = CustomLogisticRegression(lr=0.1, max_epochs=1000)\nlog_reg.fit(X_train_class, y_train_class)\ny_pred_class = log_reg.predict(X_test_class)\n\naccuracy = accuracy_score(y_test_class, y_pred_class)\nf1 = f1_score(y_test_class, y_pred_class, average=\"weighted\")\n\n\nprint(f\"Custom Logistic Regression - Accuracy: {accuracy:.4f}, F1-Score: {f1:.4f}\")\n\nlin_reg = CustomLinearRegression()\nlin_reg.fit(X_train_reg, y_train_reg)\ny_pred_reg = lin_reg.predict(X_test_reg)\n\nrmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"Custom Linear Regression - RMSE: {rmse:.4f}, R²: {r2:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T19:59:25.472815Z","iopub.execute_input":"2025-12-14T19:59:25.473130Z","iopub.status.idle":"2025-12-14T19:59:25.603787Z","shell.execute_reply.started":"2025-12-14T19:59:25.473110Z","shell.execute_reply":"2025-12-14T19:59:25.602839Z"}},"outputs":[{"name":"stdout","text":"Custom Logistic Regression - Accuracy: 0.0611, F1-Score: 0.0189\nCustom Linear Regression - RMSE: 9.7967, R²: 0.6275\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Точность и F1-Score логистической модели сильно упали, а показатели линейной - остались примерно теми же.","metadata":{}}]}
